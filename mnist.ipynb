{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.546782\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.441651\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.280679\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.385352\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.355828\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.305017\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.313089\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.321938\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.339760\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.408270\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.322049\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.286695\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.407968\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.315266\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.480804\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.354759\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.438514\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.155563\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.478001\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.328118\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.271733\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.304447\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.288231\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.183892\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.335314\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.234655\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.178521\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.253387\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.288466\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.199047\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.319567\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.311990\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.253834\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.168905\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.451890\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.166279\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.280798\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.386110\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.206824\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.397646\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.324901\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.237611\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.220432\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.162109\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.279977\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.187787\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.354993\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.433175\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.378829\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.353411\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 9206/10000 (92%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.onnx\n",
    "\n",
    "# MNIST Dataset and DataLoader for both training and testing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "# Define the Neural Network Model\n",
    "class SimpleMNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleMNIST, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "class SimplestMNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimplestMNIST, self).__init__()\n",
    "        self.fc = nn.Linear(28*28, 10)  # One fully connected layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "model = SimplestMNIST()\n",
    "\n",
    "# Training Parameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(5):  # 5 epochs for demonstration, increase as needed\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}\")\n",
    "\n",
    "# Testing Loop\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        output = model(data)\n",
    "        test_loss += criterion(output, target).item()  # Sum up batch loss\n",
    "        pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max log-probability\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%onnx::Reshape_0 : Float(1, 1, 28, 28, strides=[784, 784, 28, 1], requires_grad=0, device=cpu),\n",
      "      %fc.weight : Float(10, 784, strides=[784, 1], requires_grad=1, device=cpu),\n",
      "      %fc.bias : Float(10, strides=[1], requires_grad=1, device=cpu)):\n",
      "  %/Constant_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=  -1  784 [ CPULongType{2} ], onnx_name=\"/Constant\"](), scope: __main__.SimplestMNIST:: # /var/folders/_r/rcjcpfc15fxf66bn1kd3l1r00000gn/T/ipykernel_18344/2081141353.py:44:0\n",
      "  %/Reshape_output_0 : Float(1, 784, strides=[784, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/Reshape\"](%onnx::Reshape_0, %/Constant_output_0), scope: __main__.SimplestMNIST:: # /var/folders/_r/rcjcpfc15fxf66bn1kd3l1r00000gn/T/ipykernel_18344/2081141353.py:44:0\n",
      "  %5 : Float(1, 10, strides=[10, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/fc/Gemm\"](%/Reshape_output_0, %fc.weight, %fc.bias), scope: __main__.SimplestMNIST::/torch.nn.modules.linear.Linear::fc # /opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  return (%5)\n",
      "\n",
      "Model has been exported to ONNX format.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Export the model to ONNX format\n",
    "dummy_input = torch.randn(1, 1, 28, 28)  # Dummy input for the model\n",
    "torch.onnx.export(model, dummy_input, \"simple_mnist.onnx\", verbose=True)\n",
    "\n",
    "print(\"Model has been exported to ONNX format.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
